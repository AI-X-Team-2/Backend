import os
import re
import json
import torch
from fastapi.middleware.cors import CORSMiddleware
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
from openai import AsyncOpenAI
from dotenv import load_dotenv


# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ë˜ëŠ” ["http://localhost:3000"] ë“±
    allow_credentials=True,
    allow_methods=["*"],  # "POST", "GET", "OPTIONS" ë“±
    allow_headers=["*"],
)

# ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU ë˜ëŠ” CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ê°ì • ë¶„ì„ íŒŒì´í”„ë¼ì¸
classifier = pipeline(
    "text-classification",
    model="j-hartmann/emotion-english-distilroberta-base",
    top_k=None,
    device=0 if device.type == "cuda" else -1
)

# ë²ˆì—­ê¸° íŒŒì´í”„ë¼ì¸ ì„¤ì •
model_name = "facebook/nllb-200-distilled-600M"
tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)
translator = pipeline(
    "translation",
    model=model,
    tokenizer=tokenizer,
    src_lang="kor_Hang",
    tgt_lang="eng_Latn",
    device=0 if device.type == "cuda" else -1
)

# OpenAI ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ìš”ì²­ ëª¨ë¸
class DreamRequest(BaseModel):
    content: str

# ì‘ë‹µ ëª¨ë¸
class DreamResponse(BaseModel):
    original_text: str
    overview: str
    theme_analysis: str
    detail_analysis: str
    real_life_connection: str
    comforting_advice: str

@app.post("/interpret", response_model=DreamResponse)
async def interpret_dream(request: DreamRequest):
    try:
        # 1. ì›ë¬¸
        dream_text = request.content

        # 2. ë²ˆì—­
        translation_result = translator(dream_text)
        if not translation_result or "translation_text" not in translation_result[0]:
            raise HTTPException(status_code=500, detail="ë²ˆì—­ ê²°ê³¼ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        translated_text = translation_result[0]["translation_text"]

        # 3. ê°ì • ë¶„ì„
        emotion_result = classifier(translated_text)
        if not emotion_result:
            raise HTTPException(status_code=500, detail="ê°ì • ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        if len(emotion_result) == 1 and isinstance(emotion_result[0], list):
            emotion_result = emotion_result[0]

        top_emotion = max(emotion_result, key=lambda x: x["score"])
        if top_emotion["label"] == "neutral":
            filtered = [e for e in emotion_result if e["label"] != "neutral"]
            if filtered:
                top_emotion = max(filtered, key=lambda x: x["score"])

        # 4. GPT í”„ë¡¬í”„íŠ¸
        prompt = f"""
        
- ê¿ˆ ë‚´ìš©: "{translated_text}"
- ê°ì •: "{top_emotion['label']}" (score: {top_emotion['score']:.2f})
ë‹¤ìŒì€ ì•…ëª½ì— ëŒ€í•œ ì‹¬ë¦¬í•™ì  í•´ì„ ìš”ì²­ì…ë‹ˆë‹¤. ì•„ë˜ ê°ì • ë° ê¿ˆ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ, ìš”ì²­í•œ 5ê°€ì§€ í•­ëª©ì„ ê°ê° **í•œêµ­ì–´ë¡œ** í•´ì„í•´ ì£¼ì„¸ìš”.
1. **ê°œìš” (Overview)**:
ì•…ëª½ì˜ ì£¼ìš” ë‚´ìš©ê³¼ ì§€ë°°ì ì¸ ê°ì •ì„ 3ì¤„ ì´ìƒ 4ì¤„ ì´ë‚´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

2. **ê¿ˆì˜ ì£¼ì œ ê¸°ë°˜ ë¶„ì„ (Dream Theme Analysis)**:
í•µì‹¬ ì£¼ì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸ì •ì ì¸ ë©”ì‹œì§€ë‚˜ í¬ë§ì ì¸ í•´ì„ì„ 5ì¤„ì´ìƒ 6ì¤„ ì´ë‚´ë¡œì„¤ëª…í•´ì£¼ì„¸ìš”.theme_analysisì— ì´ í•´ì„ì„ ëŒ€ì…í•´ì£¼ì„¸ìš”.

3. **ì„¸ë¶€ìš”ì†Œ ë¶„ì„ (Detailed Element Analysis)**:
ê¿ˆì˜ êµ¬ì²´ì ì¸ ìƒí™©ê³¼ ê°ì •({top_emotion['label']})ì„ ë¶„ì„í•˜ê³ , í•µì‹¬ë‹¨ì–´ 2~3ê°œë¥¼ ë½‘ì•„ì„œ ê° í•µì‹¬ë‹¨ì–´ë³„ë¡œ 2ì¤„ ì´ìƒ 3ì¤„ ì´ë‚´ë¡œì„¤ëª…í•´ì£¼ì„¸ìš”.
ë‹¤ìŒì˜ ì˜ˆì‹œì˜ í˜•ì‹ë§Œ ì°¸ê³ ë¡œ í•˜ê³  ë‚´ìš©ì€ ì ˆëŒ€ ë”°ë¼í•˜ì§€ ë§ê³  ë°˜ë“œì‹œ ìƒˆë¡œ ìƒì„±í•´ì•¼í•œë‹¤. **í•œ ë¬¸ì¥ì”© ì¤„ë°”ê¿ˆ(\n)ìœ¼ë¡œ êµ¬ë¶„ëœ í•˜ë‚˜ì˜ ë¬¸ìì—´** í˜•íƒœë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”:

ë‹¹ì‹ ì´ ì¶”ì¶œí•œ í•µì‹¬ë‹¨ì–´ëª…ì„ ì—¬ê¸°ì— ì‘ì„± : ë¶„ì„í•œ ë‚´ìš©ì„ ì´ê³³ì— ì‘ì„± ì´ ë’¤ì— ì¤„ë°”ê¿ˆ(\n)ì„ í¬í•¨í•´ì£¼ì„¸ìš”. 
ì´í˜•ì‹ì„ ì ˆëŒ€ ë²—ì–´ë‚˜ê±°ë‚˜ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
ë¬´ì¡°ê±´ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.

ê·¸ë¦¬ê³  ì´ë¥¼ detail_analysis ë³€ìˆ˜ì— ë¬¸ìì—´(String) í˜•íƒœë¡œ ë„£ì–´ì£¼ì„¸ìš”.

4. **ìƒí™œ ì† ì—°ê´€ì„± ìœ ì¶” (Real-life Connection Inference)**:
ì´ ê¿ˆì´ ì¼ìƒ, ê³ ë¯¼, ë¬´ì˜ì‹ê³¼ ì–´ë–»ê²Œ ì—°ê²°ë˜ëŠ”ì§€ 4ì¤„ì´ìƒ 6ì¤„ ì´ë‚´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”. ì´ë¥¼ real_life_connection ë³€ìˆ˜ì— ë„£ì–´ì£¼ì„¸ìš”.

5. **ìœ„ë¡œ ì¡°ì–¸ ë° ê²°ë¡  (Comforting Advice and Conclusion)**:
ê°ì •({top_emotion['label']})ì— ê³µê°í•˜ë©° ë”°ëœ»í•œ ìœ„ë¡œì™€ ì¡°ì–¸ì„ í¬í•¨í•˜ë©° ìœ„ì˜ ëª¨ë“  í•´ì„ ë‚´ìš©ì„ í¬ê´„í•˜ëŠ” ê²°ë¡ ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
4ì¤„ì´ìƒ 6ì¤„ ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
ì´ë¥¼ comforting_advice ì— ë„£ì–´ì£¼ì„¸ìš”.

 ì•„ë˜ í˜•ì‹ì„ **ì •í™•íˆ ê·¸ëŒ€ë¡œ** ì‚¬ìš©í•˜ì—¬ JSON ì‘ë‹µì„ ë§Œë“¤ì–´ ì£¼ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

{{
  "overview": "...",
  "theme_analysis": "...",
  "detail_analysis": "...",
  "real_life_connection": "...",
  "comforting_advice": "..."
}}
ë¶„ì„ ë‚´ìš©ì€ ë°˜ë“œì‹œ ë‹¤ìŒ 5ê°€ì§€ í‚¤ë¥¼ ê°€ì§„ ë‹¨ì¼ JSON ê°ì²´ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤: "overview", "theme_analysis", "detail_analysis", "real_life_connection", "comforting_advice".
ëª¨ë“  ê°’ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
ì•ë’¤ì— ì–´ë– í•œ ì„¤ëª…, í•´ì„, ì–¸ê¸‰ë„ ë¶™ì´ì§€ ë§ˆì„¸ìš”.
JSON ì•ˆì˜ ê°’ ì™¸ì— ì•„ë¬´ê²ƒë„ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”.

 ë°˜ë“œì‹œ ìœ„ JSON êµ¬ì¡°ë§Œ í¬í•¨í•˜ë©°, ê° ê°’ì€ í¬ë§ì ì¸ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
ì ˆëŒ€ ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ëŸ­(```json ë“±)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
 ë‹¤ë¥¸ ì„¤ëª…, í•´ì„, í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""

        # 5. GPT í˜¸ì¶œ
        completion = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a dream interpretation expert who always replies in JSON."},
                {"role": "user", "content": prompt}
            ]
        )

        # 6. GPT ì‘ë‹µ íŒŒì‹±
        gpt_raw_response = completion.choices[0].message.content.strip()

        # â¬‡ï¸ ì—¬ê¸°ì— ì¶”ê°€
        print("ğŸ”¥ GPT ì›ë³¸ ì‘ë‹µ:")
        print(gpt_raw_response)

        clean_response = re.sub(r"^```json|```$", "", gpt_raw_response, flags=re.MULTILINE).strip()

        # â¬‡ï¸ ì—¬ê¸°ì—ë„ ì¶”ê°€ ê°€ëŠ¥
        print("âœ… ì •ì œëœ ì‘ë‹µ:")
        print(clean_response)

        try:
            gpt_data = json.loads(clean_response)
        except json.JSONDecodeError:
            raise HTTPException(status_code=500, detail="GPT ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤:\n" + gpt_raw_response)

        # 7. í‚¤ ìœ íš¨ì„± ê²€ì‚¬
        required_keys = [
            "overview",
            "theme_analysis",
            "detail_analysis",
            "real_life_connection",
            "comforting_advice"
        ]
        missing_keys = [k for k in required_keys if k not in gpt_data]
        if missing_keys:
            raise HTTPException(
                status_code=500,
                detail=f"GPT ì‘ë‹µì—ì„œ ëˆ„ë½ëœ í‚¤: {', '.join(missing_keys)}"
            )

        # 8. ì‘ë‹µ ë°˜í™˜
        return DreamResponse(
            original_text=dream_text,
            overview=gpt_data["overview"],
            theme_analysis=gpt_data["theme_analysis"],
            detail_analysis=gpt_data["detail_analysis"],
            real_life_connection=gpt_data["real_life_connection"],
            comforting_advice=gpt_data["comforting_advice"]
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

import os
import re
import json
import torch
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
from openai import AsyncOpenAI
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

app = FastAPI()

# ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU ë˜ëŠ” CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ê°ì • ë¶„ì„ íŒŒì´í”„ë¼ì¸
classifier = pipeline(
    "text-classification",
    model="j-hartmann/emotion-english-distilroberta-base",
    top_k=None,
    device=0 if device.type == "cuda" else -1
)

# ë²ˆì—­ê¸° íŒŒì´í”„ë¼ì¸ ì„¤ì •
model_name = "facebook/nllb-200-distilled-600M"
tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)
translator = pipeline(
    "translation",
    model=model,
    tokenizer=tokenizer,
    src_lang="kor_Hang",
    tgt_lang="eng_Latn",
    device=0 if device.type == "cuda" else -1
)

# OpenAI ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ìš”ì²­ ëª¨ë¸
class DreamRequest(BaseModel):
    content: str

# ì‘ë‹µ ëª¨ë¸
class DreamResponse(BaseModel):
    original_text: str
    overview: str
    theme_analysis: str
    detail_analysis: str
    real_life_connection: str
    comforting_advice: str

@app.post("/interpret", response_model=DreamResponse)
async def interpret_dream(request: DreamRequest):
    try:
        # 1. ì›ë¬¸
        dream_text = request.content

        # 2. ë²ˆì—­
        translation_result = translator(dream_text)
        if not translation_result or "translation_text" not in translation_result[0]:
            raise HTTPException(status_code=500, detail="ë²ˆì—­ ê²°ê³¼ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        translated_text = translation_result[0]["translation_text"]

        # 3. ê°ì • ë¶„ì„
        emotion_result = classifier(translated_text)
        if not emotion_result:
            raise HTTPException(status_code=500, detail="ê°ì • ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        if len(emotion_result) == 1 and isinstance(emotion_result[0], list):
            emotion_result = emotion_result[0]

        top_emotion = max(emotion_result, key=lambda x: x["score"])
        if top_emotion["label"] == "neutral":
            filtered = [e for e in emotion_result if e["label"] != "neutral"]
            if filtered:
                top_emotion = max(filtered, key=lambda x: x["score"])

        # 4. GPT í”„ë¡¬í”„íŠ¸
        prompt = f"""
ë‹¤ìŒì€ ì•…ëª½ì— ëŒ€í•œ ì‹¬ë¦¬í•™ì  í•´ì„ ìš”ì²­ì…ë‹ˆë‹¤. ì•„ë˜ ê°ì • ë° ê¿ˆ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ, ìš”ì²­í•œ 5ê°€ì§€ í•­ëª©ì„ ê°ê° **í•œêµ­ì–´ë¡œ** í•´ì„í•´ ì£¼ì„¸ìš”.

- ê¿ˆ ë‚´ìš©: "{translated_text}"
- ê°ì •: "{top_emotion['label']}" (score: {top_emotion['score']:.2f})

ğŸ¯ ì•„ë˜ í˜•ì‹ì„ **ì •í™•íˆ ê·¸ëŒ€ë¡œ** ì‚¬ìš©í•˜ì—¬ JSON ì‘ë‹µì„ ë§Œë“¤ì–´ ì£¼ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

{{
  "overview": "...",
  "theme_analysis": "...",
  "detail_analysis": "...",
  "real_life_connection": "...",
  "comforting_advice": "..."
}}

â— ë°˜ë“œì‹œ ìœ„ JSON êµ¬ì¡°ë§Œ í¬í•¨í•˜ë©°, ê° ê°’ì€ ê°„ê²°í•˜ê³  í¬ë§ì ì¸ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
â— ì ˆëŒ€ ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ëŸ­(```json ë“±)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
â— ë‹¤ë¥¸ ì„¤ëª…, í•´ì„, í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""

        # 5. GPT í˜¸ì¶œ
        completion = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a dream interpretation expert who always replies in JSON."},
                {"role": "user", "content": prompt}
            ]
        )

        # 6. GPT ì‘ë‹µ íŒŒì‹±
        gpt_raw_response = completion.choices[0].message.content.strip()
        clean_response = re.sub(r"^```json|```$", "", gpt_raw_response, flags=re.MULTILINE).strip()

        try:
            gpt_data = json.loads(clean_response)
        except json.JSONDecodeError:
            raise HTTPException(status_code=500, detail="GPT ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤:\n" + gpt_raw_response)

        # 7. í‚¤ ìœ íš¨ì„± ê²€ì‚¬
        required_keys = [
            "overview",
            "theme_analysis",
            "detail_analysis",
            "real_life_connection",
            "comforting_advice"
        ]
        missing_keys = [k for k in required_keys if k not in gpt_data]
        if missing_keys:
            raise HTTPException(
                status_code=500,
                detail=f"GPT ì‘ë‹µì—ì„œ ëˆ„ë½ëœ í‚¤: {', '.join(missing_keys)}"
            )

        # 8. ì‘ë‹µ ë°˜í™˜
        return DreamResponse(
            original_text=dream_text,
            overview=gpt_data["overview"],
            theme_analysis=gpt_data["theme_analysis"],
            detail_analysis=gpt_data["detail_analysis"],
            real_life_connection=gpt_data["real_life_connection"],
            comforting_advice=gpt_data["comforting_advice"]
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

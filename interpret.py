import os
import re
import json
import torch
from fastapi.middleware.cors import CORSMiddleware
import random
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
from openai import AsyncOpenAI
from dotenv import load_dotenv

# ìœ íŠœë¸Œ API ë° ë¹„ë™ê¸° ì²˜ë¦¬ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from fastapi.concurrency import run_in_threadpool

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ë˜ëŠ” ["http://localhost:3000"] ë“±
    allow_credentials=True,
    allow_methods=["*"],  # "POST", "GET", "OPTIONS" ë“±
    allow_headers=["*"],
)

# ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU ë˜ëŠ” CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ê°ì • ë¶„ì„ íŒŒì´í”„ë¼ì¸
classifier = pipeline(
    "text-classification",
    model="j-hartmann/emotion-english-distilroberta-base",
    top_k=None,
    device=0 if device.type == "cuda" else -1
)

# ë²ˆì—­ê¸° íŒŒì´í”„ë¼ì¸ ì„¤ì •
model_name = "facebook/nllb-200-distilled-600M"
tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)
translator = pipeline(
    "translation",
    model=model,
    tokenizer=tokenizer,
    src_lang="kor_Hang",
    tgt_lang="eng_Latn",
    device=0 if device.type == "cuda" else -1
)

# OpenAI ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# (ìˆ˜ì •) ì¼ë°˜ì ì¸ K-POP í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬´ì‘ìœ„ë¡œ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜
def get_kpop_playlist_url() -> str:
    """ë¯¸ë¦¬ ì •ì˜ëœ ê²€ìƒ‰ì–´ ëª©ë¡ì—ì„œ ë¬´ì‘ìœ„ë¡œ K-POP í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•˜ì—¬ URLì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    api_key = os.getenv("YOUTUBE_API_KEY")
    if not api_key:
        return "YOUTUBE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    # (ìˆ˜ì •) ë¯¸ë¦¬ ì •ì˜ëœ ì¼ë°˜ì ì¸ K-POP í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ê²€ìƒ‰ì–´ ë¦¬ìŠ¤íŠ¸
    general_queries = [
        "ì‹ ë‚˜ëŠ” ì¼€ì´íŒ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸",
        "ìš°ìš¸í• ë•Œ ë“£ëŠ” ì¼€ì´íŒ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸",
        "ìƒˆë²½ ê°ì„± ì¼€ì´íŒ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸",
        "ê³µë¶€í•  ë•Œ ë“£ëŠ” ì¼€ì´íŒ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸",
        "ìš´ë™í•  ë•Œ ë“£ëŠ” ì‹ ë‚˜ëŠ” ì¼€ì´íŒ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸",
        "íŒŒí‹°í•  ë•Œ ë“£ê¸° ì¢‹ì€ ì‹ ë‚˜ëŠ” ì¼€ì´íŒ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸",
        "ë¹„ ì˜¤ëŠ” ë‚  ë“£ê¸° ì¢‹ì€ ê°ì„± ì¼€ì´íŒ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸",
        "ì—¬ë¦„ì— ë“£ê¸° ì¢‹ì€ ì¼€ì´íŒ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸",
        "ê²¨ìš¸ì— ë“£ê¸° ì¢‹ì€ ì¼€ì´íŒ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸",
        "ë´„ì— ë“£ê¸° ì¢‹ì€ ì¼€ì´íŒ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸",
        "ê°€ì„ì— ë“£ê¸° ì¢‹ì€ ì¼€ì´íŒ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸",
    ]

    # (ìˆ˜ì •) ë¦¬ìŠ¤íŠ¸ì—ì„œ ê²€ìƒ‰ì–´ í•˜ë‚˜ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ íƒ
    search_query = random.choice(general_queries)
    print(f"Searching YouTube with query: {search_query}") # ë””ë²„ê¹…ìš© ë¡œê·¸

    try:
        youtube = build('youtube', 'v3', developerKey=api_key)
        
        search_response = youtube.search().list(
            q=search_query,
            part='id',
            type='playlist',
            maxResults=10   #í”Œë ˆì´ìŠ¤íŠ¸ 10ê°œ
        ).execute()

        if not search_response.get("items"):
            return f"https://www.youtube.com/results?search_query={search_query.replace(' ', '+')}"

        selected_playlist = random.choice(search_response["items"])
        playlist_id = selected_playlist["id"]["playlistId"]

        playlist_items_response = youtube.playlistItems().list(
            part='snippet',
            playlistId=playlist_id,
            maxResults=1
        ).execute()

        if not playlist_items_response.get("items"):
            return f"https://www.youtube.com/playlist?list={playlist_id}"

        video_id = playlist_items_response["items"][0]["snippet"]["resourceId"]["videoId"]
        
        return f"https://www.youtube.com/watch?v={video_id}&list={playlist_id}"

    except HttpError as e:
        print(f"An HTTP error {e.resp.status} occurred:\n{e.content}")
        return "https://www.youtube.com/results?search_query=kpop+playlist"
    except Exception as e:
        print(f"An error occurred while fetching YouTube playlist: {e}")
        return "í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."




# ìš”ì²­ ëª¨ë¸
class DreamRequest(BaseModel):
    content: str

# ì‘ë‹µ ëª¨ë¸
class DreamResponse(BaseModel):
    original_text: str
    overview: str
    theme_analysis: str
    detail_analysis: str
    real_life_connection: str
    comforting_advice: str
    image_url: str
    playlist_url: str

@app.post("/interpret", response_model=DreamResponse)
async def interpret_dream(request: DreamRequest):
    try:
        # 1. ì›ë¬¸
        dream_text = request.content

        # 2. ë²ˆì—­
        translation_result = translator(dream_text)
        if not translation_result or "translation_text" not in translation_result[0]:
            raise HTTPException(status_code=500, detail="ë²ˆì—­ ê²°ê³¼ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        translated_text = translation_result[0]["translation_text"]

        # 3. ê°ì • ë¶„ì„
        emotion_result = classifier(translated_text)
        if not emotion_result:
            raise HTTPException(status_code=500, detail="ê°ì • ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        if len(emotion_result) == 1 and isinstance(emotion_result[0], list):
            emotion_result = emotion_result[0]

        top_emotion = max(emotion_result, key=lambda x: x["score"])
        if top_emotion["label"] == "neutral":
            filtered = [e for e in emotion_result if e["label"] != "neutral"]
            if filtered:
                top_emotion = max(filtered, key=lambda x: x["score"])


        # (ìˆ˜ì •) ê°ì • ë¶„ì„ ê²°ê³¼ì™€ ìƒê´€ì—†ì´ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ í•¨ìˆ˜ í˜¸ì¶œ
        playlist_url = await run_in_threadpool(get_kpop_playlist_url)

        # 4. GPT í”„ë¡¬í”„íŠ¸
        prompt = f"""
        
        - ê¿ˆ ë‚´ìš©: "{translated_text}"
        - ê°ì •: "{top_emotion['label']}" (score: {top_emotion['score']:.2f})
        ë‹¤ìŒì€ ì•…ëª½ì— ëŒ€í•œ ì‹¬ë¦¬í•™ì  í•´ì„ ìš”ì²­ì…ë‹ˆë‹¤. ì•„ë˜ ê°ì • ë° ê¿ˆ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ, ìš”ì²­í•œ 5ê°€ì§€ í•­ëª©ì„ ê°ê° **í•œêµ­ì–´ë¡œ** í•´ì„í•´ ì£¼ì„¸ìš”.
        1. **ê°œìš” (Overview)**:
        ì•…ëª½ì˜ ì£¼ìš” ë‚´ìš©ê³¼ ì§€ë°°ì ì¸ ê°ì •ì„ 3ì¤„ ì´ìƒ 4ì¤„ ì´ë‚´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

        2. **ê¿ˆì˜ ì£¼ì œ ê¸°ë°˜ ë¶„ì„ (Dream Theme Analysis)**:
        í•µì‹¬ ì£¼ì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸ì •ì ì¸ ë©”ì‹œì§€ë‚˜ í¬ë§ì ì¸ í•´ì„ì„ 5ì¤„ì´ìƒ 6ì¤„ ì´ë‚´ë¡œì„¤ëª…í•´ì£¼ì„¸ìš”.theme_analysisì— ì´ í•´ì„ì„ ëŒ€ì…í•´ì£¼ì„¸ìš”.

        3. **ì„¸ë¶€ìš”ì†Œ ë¶„ì„ (Detailed Element Analysis)**:
        ê¿ˆì˜ êµ¬ì²´ì ì¸ ìƒí™©ê³¼ ê°ì •({top_emotion['label']})ì„ ë¶„ì„í•˜ê³ , í•µì‹¬ë‹¨ì–´ 2~3ê°œë¥¼ ë½‘ì•„ì„œ ê° í•µì‹¬ë‹¨ì–´ë³„ë¡œ 2ì¤„ ì´ìƒ 3ì¤„ ì´ë‚´ë¡œì„¤ëª…í•´ì£¼ì„¸ìš”.
        ë‹¤ìŒì˜ ì˜ˆì‹œì˜ í˜•ì‹ë§Œ ì°¸ê³ ë¡œ í•˜ê³  ë‚´ìš©ì€ ì ˆëŒ€ ë”°ë¼í•˜ì§€ ë§ê³  ë°˜ë“œì‹œ ìƒˆë¡œ ìƒì„±í•´ì•¼í•œë‹¤. **í•œ ë¬¸ì¥ì”© ì¤„ë°”ê¿ˆ(\n)ìœ¼ë¡œ êµ¬ë¶„ëœ í•˜ë‚˜ì˜ ë¬¸ìì—´** í˜•íƒœë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”:

        ë‹¹ì‹ ì´ ì¶”ì¶œí•œ í•µì‹¬ë‹¨ì–´ëª…ì„ ì—¬ê¸°ì— ì‘ì„± : ë¶„ì„í•œ ë‚´ìš©ì„ ì´ê³³ì— ì‘ì„± ì´ ë’¤ì— ì¤„ë°”ê¿ˆ(\n)ì„ í¬í•¨í•´ì£¼ì„¸ìš”. 
        ì´í˜•ì‹ì„ ì ˆëŒ€ ë²—ì–´ë‚˜ê±°ë‚˜ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
        ë¬´ì¡°ê±´ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.

        ê·¸ë¦¬ê³  ì´ë¥¼ detail_analysis ë³€ìˆ˜ì— ë¬¸ìì—´(String) í˜•íƒœë¡œ ë„£ì–´ì£¼ì„¸ìš”.

        4. **ìƒí™œ ì† ì—°ê´€ì„± ìœ ì¶” (Real-life Connection Inference)**:
        ì´ ê¿ˆì´ ì¼ìƒ, ê³ ë¯¼, ë¬´ì˜ì‹ê³¼ ì–´ë–»ê²Œ ì—°ê²°ë˜ëŠ”ì§€ 4ì¤„ì´ìƒ 6ì¤„ ì´ë‚´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”. ì´ë¥¼ real_life_connection ë³€ìˆ˜ì— ë„£ì–´ì£¼ì„¸ìš”.

        5. **ìœ„ë¡œ ì¡°ì–¸ ë° ê²°ë¡  (Comforting Advice and Conclusion)**:
        ê°ì •({top_emotion['label']})ì— ê³µê°í•˜ë©° ë”°ëœ»í•œ ìœ„ë¡œì™€ ì¡°ì–¸ì„ í¬í•¨í•˜ë©° ìœ„ì˜ ëª¨ë“  í•´ì„ ë‚´ìš©ì„ í¬ê´„í•˜ëŠ” ê²°ë¡ ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
        4ì¤„ì´ìƒ 6ì¤„ ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        ì´ë¥¼ comforting_advice ì— ë„£ì–´ì£¼ì„¸ìš”.

        ì•„ë˜ í˜•ì‹ì„ **ì •í™•íˆ ê·¸ëŒ€ë¡œ** ì‚¬ìš©í•˜ì—¬ JSON ì‘ë‹µì„ ë§Œë“¤ì–´ ì£¼ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

        {{
        "overview": "...",
        "theme_analysis": "...",
        "detail_analysis": "...",
        "real_life_connection": "...",
        "comforting_advice": "..."
        }}
        ë¶„ì„ ë‚´ìš©ì€ ë°˜ë“œì‹œ ë‹¤ìŒ 5ê°€ì§€ í‚¤ë¥¼ ê°€ì§„ ë‹¨ì¼ JSON ê°ì²´ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤: "overview", "theme_analysis", "detail_analysis", "real_life_connection", "comforting_advice".
        ëª¨ë“  ê°’ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        ì•ë’¤ì— ì–´ë– í•œ ì„¤ëª…, í•´ì„, ì–¸ê¸‰ë„ ë¶™ì´ì§€ ë§ˆì„¸ìš”.
        JSON ì•ˆì˜ ê°’ ì™¸ì— ì•„ë¬´ê²ƒë„ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”.

        ë°˜ë“œì‹œ ìœ„ JSON êµ¬ì¡°ë§Œ í¬í•¨í•˜ë©°, ê° ê°’ì€ í¬ë§ì ì¸ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
        ì ˆëŒ€ ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ëŸ­(```json ë“±)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
        ë‹¤ë¥¸ ì„¤ëª…, í•´ì„, í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
        """

        # 5. GPT í˜¸ì¶œ
        completion = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a dream interpretation expert who always replies in JSON."},
                {"role": "user", "content": prompt}
            ]
        )

        # 6. GPT ì‘ë‹µ íŒŒì‹±
        gpt_raw_response = completion.choices[0].message.content.strip()

        # â¬‡ï¸ ì—¬ê¸°ì— ì¶”ê°€
        print("ğŸ”¥ GPT ì›ë³¸ ì‘ë‹µ:")
        print(gpt_raw_response)

        clean_response = re.sub(r"^```json|```$", "", gpt_raw_response, flags=re.MULTILINE).strip()

        # â¬‡ï¸ ì—¬ê¸°ì—ë„ ì¶”ê°€ ê°€ëŠ¥
        print("âœ… ì •ì œëœ ì‘ë‹µ:")
        print(clean_response)

        try:
            gpt_data = json.loads(clean_response)
        except json.JSONDecodeError:
            raise HTTPException(status_code=500, detail="GPT ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤:\n" + gpt_raw_response)

        required_keys = [
            "overview", "theme_analysis", "detail_analysis",
            "real_life_connection", "comforting_advice"
        ]
        if not all(key in gpt_data for key in required_keys):
            missing_keys = [k for k in required_keys if k not in gpt_data]
            raise HTTPException(status_code=500, detail=f"GPT ì‘ë‹µì—ì„œ ëˆ„ë½ëœ í‚¤: {', '.join(missing_keys)}")
            
        image_prompt = f"""
        A surreal and atmospheric digital painting inspired by a dream.
        The scene depicts: {gpt_data.get('overview', translated_text)}.
        The dominant emotion is '{top_emotion['label']}'.
        Style: ethereal, dreamlike, evocative, rich in symbolism.
        IMPORTANT: Do NOT include any text, letters, or words in the image.
        """
            
        image_response = await client.images.generate(
            model="dall-e-3",
            prompt=image_prompt,
            n=1,
            size="1024x1024",
            quality="standard",
            response_format="url"
        )
        
        image_url = image_response.data[0].url

        return DreamResponse(
            original_text=dream_text,
            overview=gpt_data["overview"],
            theme_analysis=gpt_data["theme_analysis"],
            detail_analysis=gpt_data["detail_analysis"],
            real_life_connection=gpt_data["real_life_connection"],
            comforting_advice=gpt_data["comforting_advice"],
            image_url=image_url,
            playlist_url=playlist_url
        )

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))